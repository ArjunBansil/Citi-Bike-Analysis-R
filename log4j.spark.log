17/07/30 10:31:35 INFO SparkContext: Running Spark version 1.6.2
17/07/30 10:31:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/07/30 10:31:35 INFO SecurityManager: Changing view acls to: Arjun Bansil
17/07/30 10:31:35 INFO SecurityManager: Changing modify acls to: Arjun Bansil
17/07/30 10:31:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Arjun Bansil); users with modify permissions: Set(Arjun Bansil)
17/07/30 10:31:36 INFO Utils: Successfully started service 'sparkDriver' on port 64308.
17/07/30 10:31:36 INFO Slf4jLogger: Slf4jLogger started
17/07/30 10:31:36 INFO Remoting: Starting remoting
17/07/30 10:31:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@127.0.0.1:64321]
17/07/30 10:31:36 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 64321.
17/07/30 10:31:36 INFO SparkEnv: Registering MapOutputTracker
17/07/30 10:31:36 INFO SparkEnv: Registering BlockManagerMaster
17/07/30 10:31:36 INFO DiskBlockManager: Created local directory at C:\Users\Arjun Bansil\AppData\Local\Temp\blockmgr-94e471df-4055-45a1-bc53-09d642342dd9
17/07/30 10:31:36 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
17/07/30 10:31:36 INFO SparkEnv: Registering OutputCommitCoordinator
17/07/30 10:31:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/07/30 10:31:36 INFO SparkUI: Started SparkUI at http://127.0.0.1:4040
17/07/30 10:31:36 INFO HttpFileServer: HTTP File server directory is C:\Users\Arjun Bansil\AppData\Local\Temp\spark-13505055-342e-485f-ac5f-82745c53e211\httpd-31e256b5-4d90-43be-b1d3-d24b2fca6b74
17/07/30 10:31:36 INFO HttpServer: Starting HTTP Server
17/07/30 10:31:36 INFO Utils: Successfully started service 'HTTP file server' on port 64326.
17/07/30 10:31:36 INFO SparkContext: Added JAR file:/C:/Users/Arjun%20Bansil/Documents/R/win-library/3.4/sparklyr/java/spark-csv_2.11-1.3.0.jar at http://127.0.0.1:64326/jars/spark-csv_2.11-1.3.0.jar with timestamp 1501425096736
17/07/30 10:31:36 INFO SparkContext: Added JAR file:/C:/Users/Arjun%20Bansil/Documents/R/win-library/3.4/sparklyr/java/commons-csv-1.1.jar at http://127.0.0.1:64326/jars/commons-csv-1.1.jar with timestamp 1501425096826
17/07/30 10:31:36 INFO SparkContext: Added JAR file:/C:/Users/Arjun%20Bansil/Documents/R/win-library/3.4/sparklyr/java/univocity-parsers-1.5.1.jar at http://127.0.0.1:64326/jars/univocity-parsers-1.5.1.jar with timestamp 1501425096835
17/07/30 10:31:36 INFO SparkContext: Added JAR file:/C:/Users/Arjun%20Bansil/Documents/R/win-library/3.4/sparklyr/java/sparklyr-1.6-2.10.jar at http://127.0.0.1:64326/jars/sparklyr-1.6-2.10.jar with timestamp 1501425096843
17/07/30 10:31:36 INFO Executor: Starting executor ID driver on host localhost
17/07/30 10:31:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64359.
17/07/30 10:31:36 INFO NettyBlockTransferService: Server created on 64359
17/07/30 10:31:36 INFO BlockManagerMaster: Trying to register BlockManager
17/07/30 10:31:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64359 with 511.1 MB RAM, BlockManagerId(driver, localhost, 64359)
17/07/30 10:31:36 INFO BlockManagerMaster: Registered BlockManager
17/07/30 10:31:37 INFO HiveContext: Initializing execution hive, version 1.2.1
17/07/30 10:31:37 INFO ClientWrapper: Inspected Hadoop version: 2.6.0
17/07/30 10:31:37 INFO ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/07/30 10:31:37 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/07/30 10:31:37 INFO ObjectStore: ObjectStore, initialize called
17/07/30 10:31:37 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/07/30 10:31:37 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/07/30 10:31:38 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
17/07/30 10:31:38 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
17/07/30 10:31:40 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/07/30 10:31:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:44 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/07/30 10:31:44 INFO ObjectStore: Initialized ObjectStore
17/07/30 10:31:44 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/07/30 10:31:44 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/07/30 10:31:44 INFO HiveMetaStore: Added admin role in metastore
17/07/30 10:31:44 INFO HiveMetaStore: Added public role in metastore
17/07/30 10:31:45 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/07/30 10:31:45 INFO HiveMetaStore: 0: get_all_databases
17/07/30 10:31:45 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_all_databases	
17/07/30 10:31:45 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/07/30 10:31:45 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/07/30 10:31:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:45 INFO SessionState: Created local directory: C:/Users/ARJUNB~1/AppData/Local/Temp/a97e6269-cfc9-46ef-bb99-828e7e497350_resources
17/07/30 10:31:45 INFO SessionState: Created HDFS directory: C:/Users/Arjun%20Bansil/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/Arjun%20Bansil/a97e6269-cfc9-46ef-bb99-828e7e497350
17/07/30 10:31:45 INFO SessionState: Created local directory: C:/Users/Arjun Bansil/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/a97e6269-cfc9-46ef-bb99-828e7e497350
17/07/30 10:31:45 INFO SessionState: Created HDFS directory: C:/Users/Arjun%20Bansil/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/Arjun%20Bansil/a97e6269-cfc9-46ef-bb99-828e7e497350/_tmp_space.db
17/07/30 10:31:45 INFO HiveContext: default warehouse location is C:\Users\Arjun Bansil\AppData\Local\rstudio\spark\Cache\spark-1.6.2-bin-hadoop2.6\tmp\hive
17/07/30 10:31:45 INFO HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/07/30 10:31:45 INFO ClientWrapper: Inspected Hadoop version: 2.6.0
17/07/30 10:31:45 INFO ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/07/30 10:31:46 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/07/30 10:31:46 INFO ObjectStore: ObjectStore, initialize called
17/07/30 10:31:46 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/07/30 10:31:46 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/07/30 10:31:46 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
17/07/30 10:31:46 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
17/07/30 10:31:47 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/07/30 10:31:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:48 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/07/30 10:31:48 INFO ObjectStore: Initialized ObjectStore
17/07/30 10:31:48 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/07/30 10:31:48 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/07/30 10:31:48 INFO HiveMetaStore: Added admin role in metastore
17/07/30 10:31:48 INFO HiveMetaStore: Added public role in metastore
17/07/30 10:31:48 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/07/30 10:31:48 INFO HiveMetaStore: 0: get_all_databases
17/07/30 10:31:48 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_all_databases	
17/07/30 10:31:48 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/07/30 10:31:48 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/07/30 10:31:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/07/30 10:31:48 INFO SessionState: Created local directory: C:/Users/ARJUNB~1/AppData/Local/Temp/7e89754c-d8ce-4f9d-a635-dd404e22c958_resources
17/07/30 10:31:48 INFO SessionState: Created HDFS directory: C:/Users/Arjun%20Bansil/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/Arjun%20Bansil/7e89754c-d8ce-4f9d-a635-dd404e22c958
17/07/30 10:31:48 INFO SessionState: Created local directory: C:/Users/Arjun Bansil/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/7e89754c-d8ce-4f9d-a635-dd404e22c958
17/07/30 10:31:48 INFO SessionState: Created HDFS directory: C:/Users/Arjun%20Bansil/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/Arjun%20Bansil/7e89754c-d8ce-4f9d-a635-dd404e22c958/_tmp_space.db
17/07/30 10:31:49 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
17/07/30 10:31:49 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
17/07/30 10:31:49 INFO SparkContext: Starting job: collect at utils.scala:195
17/07/30 10:31:49 INFO DAGScheduler: Got job 0 (collect at utils.scala:195) with 1 output partitions
17/07/30 10:31:49 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:195)
17/07/30 10:31:49 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:31:49 INFO DAGScheduler: Missing parents: List()
17/07/30 10:31:49 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at collect at utils.scala:195), which has no missing parents
17/07/30 10:31:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1968.0 B, free 1968.0 B)
17/07/30 10:31:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1230.0 B, free 3.1 KB)
17/07/30 10:31:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64359 (size: 1230.0 B, free: 511.1 MB)
17/07/30 10:31:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
17/07/30 10:31:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at collect at utils.scala:195)
17/07/30 10:31:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/07/30 10:31:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2348 bytes)
17/07/30 10:31:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/07/30 10:31:49 INFO Executor: Fetching http://127.0.0.1:64326/jars/spark-csv_2.11-1.3.0.jar with timestamp 1501425096736
17/07/30 10:31:49 INFO Utils: Fetching http://127.0.0.1:64326/jars/spark-csv_2.11-1.3.0.jar to C:\Users\Arjun Bansil\AppData\Local\Temp\spark-13505055-342e-485f-ac5f-82745c53e211\userFiles-d3ea8c55-3de2-4876-a178-41f44f5c01ce\fetchFileTemp1344247525554929382.tmp
17/07/30 10:31:49 INFO Executor: Adding file:/C:/Users/Arjun%20Bansil/AppData/Local/Temp/spark-13505055-342e-485f-ac5f-82745c53e211/userFiles-d3ea8c55-3de2-4876-a178-41f44f5c01ce/spark-csv_2.11-1.3.0.jar to class loader
17/07/30 10:31:49 INFO Executor: Fetching http://127.0.0.1:64326/jars/commons-csv-1.1.jar with timestamp 1501425096826
17/07/30 10:31:49 INFO Utils: Fetching http://127.0.0.1:64326/jars/commons-csv-1.1.jar to C:\Users\Arjun Bansil\AppData\Local\Temp\spark-13505055-342e-485f-ac5f-82745c53e211\userFiles-d3ea8c55-3de2-4876-a178-41f44f5c01ce\fetchFileTemp6236391881641335107.tmp
17/07/30 10:31:50 INFO Executor: Adding file:/C:/Users/Arjun%20Bansil/AppData/Local/Temp/spark-13505055-342e-485f-ac5f-82745c53e211/userFiles-d3ea8c55-3de2-4876-a178-41f44f5c01ce/commons-csv-1.1.jar to class loader
17/07/30 10:31:50 INFO Executor: Fetching http://127.0.0.1:64326/jars/univocity-parsers-1.5.1.jar with timestamp 1501425096835
17/07/30 10:31:50 INFO Utils: Fetching http://127.0.0.1:64326/jars/univocity-parsers-1.5.1.jar to C:\Users\Arjun Bansil\AppData\Local\Temp\spark-13505055-342e-485f-ac5f-82745c53e211\userFiles-d3ea8c55-3de2-4876-a178-41f44f5c01ce\fetchFileTemp3607822973328553049.tmp
17/07/30 10:31:50 INFO Executor: Adding file:/C:/Users/Arjun%20Bansil/AppData/Local/Temp/spark-13505055-342e-485f-ac5f-82745c53e211/userFiles-d3ea8c55-3de2-4876-a178-41f44f5c01ce/univocity-parsers-1.5.1.jar to class loader
17/07/30 10:31:50 INFO Executor: Fetching http://127.0.0.1:64326/jars/sparklyr-1.6-2.10.jar with timestamp 1501425096843
17/07/30 10:31:50 INFO Utils: Fetching http://127.0.0.1:64326/jars/sparklyr-1.6-2.10.jar to C:\Users\Arjun Bansil\AppData\Local\Temp\spark-13505055-342e-485f-ac5f-82745c53e211\userFiles-d3ea8c55-3de2-4876-a178-41f44f5c01ce\fetchFileTemp8657487513607980100.tmp
17/07/30 10:31:50 INFO Executor: Adding file:/C:/Users/Arjun%20Bansil/AppData/Local/Temp/spark-13505055-342e-485f-ac5f-82745c53e211/userFiles-d3ea8c55-3de2-4876-a178-41f44f5c01ce/sparklyr-1.6-2.10.jar to class loader
17/07/30 10:31:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 940 bytes result sent to driver
17/07/30 10:31:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 372 ms on localhost (1/1)
17/07/30 10:31:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/07/30 10:31:50 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:195) finished in 0.382 s
17/07/30 10:31:50 INFO DAGScheduler: Job 0 finished: collect at utils.scala:195, took 0.487009 s
17/07/30 10:34:34 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
17/07/30 10:34:34 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
17/07/30 10:34:34 INFO SparkContext: Starting job: collect at utils.scala:59
17/07/30 10:34:34 INFO DAGScheduler: Got job 1 (collect at utils.scala:59) with 1 output partitions
17/07/30 10:34:34 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:59)
17/07/30 10:34:34 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:34 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:34 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at map at utils.scala:56), which has no missing parents
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.4 KB, free 8.6 KB)
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 11.5 KB)
17/07/30 10:34:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64359 (size: 3.0 KB, free: 511.1 MB)
17/07/30 10:34:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at utils.scala:56)
17/07/30 10:34:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/07/30 10:34:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2348 bytes)
17/07/30 10:34:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/07/30 10:34:34 INFO GenerateUnsafeProjection: Code generated in 95.94552 ms
17/07/30 10:34:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1060 bytes result sent to driver
17/07/30 10:34:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 127 ms on localhost (1/1)
17/07/30 10:34:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/07/30 10:34:34 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:59) finished in 0.128 s
17/07/30 10:34:34 INFO DAGScheduler: Job 1 finished: collect at utils.scala:59, took 0.135019 s
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 61.8 KB, free 73.3 KB)
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 19.3 KB, free 92.7 KB)
17/07/30 10:34:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:64359 (size: 19.3 KB, free: 511.1 MB)
17/07/30 10:34:34 INFO SparkContext: Created broadcast 2 from textFile at TextFile.scala:30
17/07/30 10:34:34 INFO FileInputFormat: Total input paths to process : 1
17/07/30 10:34:34 INFO SparkContext: Starting job: take at CsvRelation.scala:249
17/07/30 10:34:34 INFO DAGScheduler: Got job 2 (take at CsvRelation.scala:249) with 1 output partitions
17/07/30 10:34:34 INFO DAGScheduler: Final stage: ResultStage 2 (take at CsvRelation.scala:249)
17/07/30 10:34:34 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:34 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:34 INFO DAGScheduler: Submitting ResultStage 2 (C:\Users\Arjun Bansil\Documents\Citi-Bike-Analysis-R\submit.csv MapPartitionsRDD[7] at textFile at TextFile.scala:30), which has no missing parents
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.1 KB, free 95.8 KB)
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1883.0 B, free 97.6 KB)
17/07/30 10:34:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:64359 (size: 1883.0 B, free: 511.1 MB)
17/07/30 10:34:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (C:\Users\Arjun Bansil\Documents\Citi-Bike-Analysis-R\submit.csv MapPartitionsRDD[7] at textFile at TextFile.scala:30)
17/07/30 10:34:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/07/30 10:34:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2414 bytes)
17/07/30 10:34:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/07/30 10:34:34 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:0+129528
17/07/30 10:34:34 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/07/30 10:34:34 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/07/30 10:34:34 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/07/30 10:34:34 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/07/30 10:34:34 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/07/30 10:34:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2437 bytes result sent to driver
17/07/30 10:34:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 36 ms on localhost (1/1)
17/07/30 10:34:34 INFO DAGScheduler: ResultStage 2 (take at CsvRelation.scala:249) finished in 0.036 s
17/07/30 10:34:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/07/30 10:34:34 INFO DAGScheduler: Job 2 finished: take at CsvRelation.scala:249, took 0.043053 s
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 208.5 KB, free 306.1 KB)
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.3 KB, free 325.5 KB)
17/07/30 10:34:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:64359 (size: 19.3 KB, free: 511.1 MB)
17/07/30 10:34:34 INFO SparkContext: Created broadcast 4 from textFile at TextFile.scala:30
17/07/30 10:34:34 INFO FileInputFormat: Total input paths to process : 1
17/07/30 10:34:34 INFO SparkContext: Starting job: aggregate at InferSchema.scala:36
17/07/30 10:34:34 INFO DAGScheduler: Got job 3 (aggregate at InferSchema.scala:36) with 2 output partitions
17/07/30 10:34:34 INFO DAGScheduler: Final stage: ResultStage 3 (aggregate at InferSchema.scala:36)
17/07/30 10:34:34 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:34 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:34 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[10] at mapPartitions at CsvRelation.scala:90), which has no missing parents
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.9 KB, free 331.4 KB)
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.4 KB, free 334.8 KB)
17/07/30 10:34:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:64359 (size: 3.4 KB, free: 511.1 MB)
17/07/30 10:34:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[10] at mapPartitions at CsvRelation.scala:90)
17/07/30 10:34:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
17/07/30 10:34:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0,PROCESS_LOCAL, 2414 bytes)
17/07/30 10:34:34 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, localhost, partition 1,PROCESS_LOCAL, 2414 bytes)
17/07/30 10:34:34 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/07/30 10:34:34 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
17/07/30 10:34:34 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:0+129528
17/07/30 10:34:34 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:129528+129528
17/07/30 10:34:34 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2176 bytes result sent to driver
17/07/30 10:34:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 147 ms on localhost (1/2)
17/07/30 10:34:34 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 2176 bytes result sent to driver
17/07/30 10:34:34 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 149 ms on localhost (2/2)
17/07/30 10:34:34 INFO DAGScheduler: ResultStage 3 (aggregate at InferSchema.scala:36) finished in 0.150 s
17/07/30 10:34:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/07/30 10:34:34 INFO DAGScheduler: Job 3 finished: aggregate at InferSchema.scala:36, took 0.155355 s
17/07/30 10:34:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:64359 in memory (size: 1883.0 B, free: 511.1 MB)
17/07/30 10:34:34 INFO ContextCleaner: Cleaned accumulator 5
17/07/30 10:34:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:64359 in memory (size: 19.3 KB, free: 511.1 MB)
17/07/30 10:34:34 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:64359 in memory (size: 3.0 KB, free: 511.1 MB)
17/07/30 10:34:34 INFO ContextCleaner: Cleaned accumulator 4
17/07/30 10:34:34 INFO ContextCleaner: Cleaned accumulator 3
17/07/30 10:34:34 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:64359 in memory (size: 1230.0 B, free: 511.1 MB)
17/07/30 10:34:34 INFO ContextCleaner: Cleaned accumulator 1
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 208.5 KB, free 445.7 KB)
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 19.3 KB, free 465.0 KB)
17/07/30 10:34:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:64359 (size: 19.3 KB, free: 511.1 MB)
17/07/30 10:34:34 INFO SparkContext: Created broadcast 6 from textFile at TextFile.scala:30
17/07/30 10:34:34 INFO FileInputFormat: Total input paths to process : 1
17/07/30 10:34:34 INFO SparkContext: Starting job: sql at null:-2
17/07/30 10:34:34 INFO DAGScheduler: Registering RDD 20 (sql at null:-2)
17/07/30 10:34:34 INFO DAGScheduler: Got job 4 (sql at null:-2) with 1 output partitions
17/07/30 10:34:34 INFO DAGScheduler: Final stage: ResultStage 5 (sql at null:-2)
17/07/30 10:34:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/07/30 10:34:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/07/30 10:34:34 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at sql at null:-2), which has no missing parents
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 16.1 KB, free 481.1 KB)
17/07/30 10:34:34 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.0 KB, free 489.1 KB)
17/07/30 10:34:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:64359 (size: 8.0 KB, free: 511.1 MB)
17/07/30 10:34:34 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at sql at null:-2)
17/07/30 10:34:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
17/07/30 10:34:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2403 bytes)
17/07/30 10:34:34 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2403 bytes)
17/07/30 10:34:34 INFO Executor: Running task 0.0 in stage 4.0 (TID 5)
17/07/30 10:34:34 INFO Executor: Running task 1.0 in stage 4.0 (TID 6)
17/07/30 10:34:34 INFO CacheManager: Partition rdd_17_0 not found, computing it
17/07/30 10:34:34 INFO CacheManager: Partition rdd_17_1 not found, computing it
17/07/30 10:34:34 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:129528+129528
17/07/30 10:34:34 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:0+129528
17/07/30 10:34:35 INFO GenerateUnsafeProjection: Code generated in 8.248892 ms
17/07/30 10:34:35 INFO MemoryStore: Block rdd_17_1 stored as values in memory (estimated size 51.1 KB, free 540.2 KB)
17/07/30 10:34:35 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 51.1 KB, free 591.3 KB)
17/07/30 10:34:35 INFO BlockManagerInfo: Added rdd_17_1 in memory on localhost:64359 (size: 51.1 KB, free: 511.0 MB)
17/07/30 10:34:35 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:64359 (size: 51.1 KB, free: 511.0 MB)
17/07/30 10:34:35 INFO GeneratePredicate: Code generated in 4.994767 ms
17/07/30 10:34:35 INFO GenerateColumnAccessor: Code generated in 17.601587 ms
17/07/30 10:34:35 INFO GenerateMutableProjection: Code generated in 5.19941 ms
17/07/30 10:34:35 INFO GenerateUnsafeProjection: Code generated in 6.009682 ms
17/07/30 10:34:35 INFO GenerateMutableProjection: Code generated in 8.384399 ms
17/07/30 10:34:35 INFO GenerateUnsafeRowJoiner: Code generated in 4.88415 ms
17/07/30 10:34:35 INFO GenerateUnsafeProjection: Code generated in 6.464793 ms
17/07/30 10:34:35 INFO Executor: Finished task 1.0 in stage 4.0 (TID 6). 3568 bytes result sent to driver
17/07/30 10:34:35 INFO Executor: Finished task 0.0 in stage 4.0 (TID 5). 3568 bytes result sent to driver
17/07/30 10:34:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 291 ms on localhost (1/2)
17/07/30 10:34:35 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 6) in 290 ms on localhost (2/2)
17/07/30 10:34:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/07/30 10:34:35 INFO DAGScheduler: ShuffleMapStage 4 (sql at null:-2) finished in 0.292 s
17/07/30 10:34:35 INFO DAGScheduler: looking for newly runnable stages
17/07/30 10:34:35 INFO DAGScheduler: running: Set()
17/07/30 10:34:35 INFO DAGScheduler: waiting: Set(ResultStage 5)
17/07/30 10:34:35 INFO DAGScheduler: failed: Set()
17/07/30 10:34:35 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at sql at null:-2), which has no missing parents
17/07/30 10:34:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 9.3 KB, free 600.6 KB)
17/07/30 10:34:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.6 KB, free 605.2 KB)
17/07/30 10:34:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:64359 (size: 4.6 KB, free: 511.0 MB)
17/07/30 10:34:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at sql at null:-2)
17/07/30 10:34:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/07/30 10:34:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7, localhost, partition 0,NODE_LOCAL, 2242 bytes)
17/07/30 10:34:35 INFO Executor: Running task 0.0 in stage 5.0 (TID 7)
17/07/30 10:34:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/07/30 10:34:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
17/07/30 10:34:35 INFO GenerateMutableProjection: Code generated in 4.689385 ms
17/07/30 10:34:35 INFO GenerateMutableProjection: Code generated in 4.299853 ms
17/07/30 10:34:35 INFO Executor: Finished task 0.0 in stage 5.0 (TID 7). 1830 bytes result sent to driver
17/07/30 10:34:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 70 ms on localhost (1/1)
17/07/30 10:34:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/07/30 10:34:35 INFO DAGScheduler: ResultStage 5 (sql at null:-2) finished in 0.071 s
17/07/30 10:34:35 INFO DAGScheduler: Job 4 finished: sql at null:-2, took 0.393856 s
17/07/30 10:34:35 INFO SparkContext: Starting job: collect at utils.scala:195
17/07/30 10:34:35 INFO DAGScheduler: Got job 5 (collect at utils.scala:195) with 1 output partitions
17/07/30 10:34:35 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:195)
17/07/30 10:34:35 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:35 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:35 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:195), which has no missing parents
17/07/30 10:34:35 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 1968.0 B, free 607.1 KB)
17/07/30 10:34:35 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 1224.0 B, free 608.3 KB)
17/07/30 10:34:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:64359 (size: 1224.0 B, free: 511.0 MB)
17/07/30 10:34:35 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:195)
17/07/30 10:34:35 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/07/30 10:34:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2348 bytes)
17/07/30 10:34:35 INFO Executor: Running task 0.0 in stage 6.0 (TID 8)
17/07/30 10:34:35 INFO Executor: Finished task 0.0 in stage 6.0 (TID 8). 940 bytes result sent to driver
17/07/30 10:34:35 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 4 ms on localhost (1/1)
17/07/30 10:34:35 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:195) finished in 0.004 s
17/07/30 10:34:35 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/07/30 10:34:35 INFO DAGScheduler: Job 5 finished: collect at utils.scala:195, took 0.009785 s
17/07/30 10:34:35 INFO ParseDriver: Parsing command: SELECT count(*) FROM `predicted`
17/07/30 10:34:36 INFO ParseDriver: Parse Completed
17/07/30 10:34:36 INFO SparkContext: Starting job: collect at utils.scala:195
17/07/30 10:34:36 INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:195)
17/07/30 10:34:36 INFO DAGScheduler: Got job 6 (collect at utils.scala:195) with 1 output partitions
17/07/30 10:34:36 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:195)
17/07/30 10:34:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/07/30 10:34:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
17/07/30 10:34:36 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:195), which has no missing parents
17/07/30 10:34:36 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 16.2 KB, free 624.5 KB)
17/07/30 10:34:36 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 8.0 KB, free 632.5 KB)
17/07/30 10:34:36 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:64359 (size: 8.0 KB, free: 511.0 MB)
17/07/30 10:34:36 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:195)
17/07/30 10:34:36 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks
17/07/30 10:34:36 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 9, localhost, partition 0,PROCESS_LOCAL, 2403 bytes)
17/07/30 10:34:36 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 10, localhost, partition 1,PROCESS_LOCAL, 2403 bytes)
17/07/30 10:34:36 INFO Executor: Running task 1.0 in stage 7.0 (TID 10)
17/07/30 10:34:36 INFO Executor: Running task 0.0 in stage 7.0 (TID 9)
17/07/30 10:34:36 INFO BlockManager: Found block rdd_17_0 locally
17/07/30 10:34:36 INFO BlockManager: Found block rdd_17_1 locally
17/07/30 10:34:36 INFO Executor: Finished task 0.0 in stage 7.0 (TID 9). 2679 bytes result sent to driver
17/07/30 10:34:36 INFO Executor: Finished task 1.0 in stage 7.0 (TID 10). 2679 bytes result sent to driver
17/07/30 10:34:36 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 9) in 22 ms on localhost (1/2)
17/07/30 10:34:36 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 10) in 23 ms on localhost (2/2)
17/07/30 10:34:36 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/07/30 10:34:36 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:195) finished in 0.024 s
17/07/30 10:34:36 INFO DAGScheduler: looking for newly runnable stages
17/07/30 10:34:36 INFO DAGScheduler: running: Set()
17/07/30 10:34:36 INFO DAGScheduler: waiting: Set(ResultStage 8)
17/07/30 10:34:36 INFO DAGScheduler: failed: Set()
17/07/30 10:34:36 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:195), which has no missing parents
17/07/30 10:34:36 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 9.4 KB, free 641.9 KB)
17/07/30 10:34:36 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.6 KB, free 646.6 KB)
17/07/30 10:34:36 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:64359 (size: 4.6 KB, free: 511.0 MB)
17/07/30 10:34:36 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at collect at utils.scala:195)
17/07/30 10:34:36 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/07/30 10:34:36 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, partition 0,NODE_LOCAL, 2242 bytes)
17/07/30 10:34:36 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
17/07/30 10:34:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/07/30 10:34:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/07/30 10:34:36 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1830 bytes result sent to driver
17/07/30 10:34:36 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 7 ms on localhost (1/1)
17/07/30 10:34:36 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/07/30 10:34:36 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:195) finished in 0.007 s
17/07/30 10:34:36 INFO DAGScheduler: Job 6 finished: collect at utils.scala:195, took 0.043759 s
17/07/30 10:34:36 INFO ParseDriver: Parsing command: SELECT *
FROM `predicted` AS `zzz1`
WHERE (0 = 1)
17/07/30 10:34:36 INFO ParseDriver: Parse Completed
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 16
17/07/30 10:34:36 INFO ContextCleaner: Cleaned shuffle 0
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 15
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 14
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 13
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 12
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 11
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 10
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 9
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 8
17/07/30 10:34:36 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:64359 in memory (size: 3.4 KB, free: 511.0 MB)
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 6
17/07/30 10:34:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:64359 in memory (size: 19.3 KB, free: 511.0 MB)
17/07/30 10:34:36 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:64359 in memory (size: 4.6 KB, free: 511.0 MB)
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 28
17/07/30 10:34:36 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:64359 in memory (size: 8.0 KB, free: 511.0 MB)
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 27
17/07/30 10:34:36 INFO ContextCleaner: Cleaned shuffle 1
17/07/30 10:34:36 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:64359 in memory (size: 1224.0 B, free: 511.0 MB)
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 18
17/07/30 10:34:36 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:64359 in memory (size: 4.6 KB, free: 511.0 MB)
17/07/30 10:34:36 INFO ContextCleaner: Cleaned accumulator 17
17/07/30 10:34:36 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:64359 in memory (size: 8.0 KB, free: 511.0 MB)
17/07/30 10:34:48 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
17/07/30 10:34:48 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
17/07/30 10:34:48 INFO SparkContext: Starting job: collect at utils.scala:195
17/07/30 10:34:48 INFO DAGScheduler: Got job 7 (collect at utils.scala:195) with 1 output partitions
17/07/30 10:34:48 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:195)
17/07/30 10:34:48 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:48 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:195), which has no missing parents
17/07/30 10:34:48 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1968.0 B, free 332.0 KB)
17/07/30 10:34:48 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1224.0 B, free 333.2 KB)
17/07/30 10:34:48 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:64359 (size: 1224.0 B, free: 511.0 MB)
17/07/30 10:34:48 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at collect at utils.scala:195)
17/07/30 10:34:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/07/30 10:34:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2651 bytes)
17/07/30 10:34:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
17/07/30 10:34:48 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 1263 bytes result sent to driver
17/07/30 10:34:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 4 ms on localhost (1/1)
17/07/30 10:34:48 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:195) finished in 0.004 s
17/07/30 10:34:48 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/07/30 10:34:48 INFO DAGScheduler: Job 7 finished: collect at utils.scala:195, took 0.008262 s
17/07/30 10:34:52 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
17/07/30 10:34:52 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
17/07/30 10:34:52 INFO SparkContext: Starting job: collect at utils.scala:59
17/07/30 10:34:52 INFO DAGScheduler: Got job 8 (collect at utils.scala:59) with 1 output partitions
17/07/30 10:34:52 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:59)
17/07/30 10:34:52 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:52 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:52 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[37] at map at utils.scala:56), which has no missing parents
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 5.4 KB, free 338.6 KB)
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.0 KB, free 341.6 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:64359 (size: 3.0 KB, free: 511.0 MB)
17/07/30 10:34:52 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[37] at map at utils.scala:56)
17/07/30 10:34:52 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/07/30 10:34:52 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, partition 0,PROCESS_LOCAL, 2651 bytes)
17/07/30 10:34:52 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
17/07/30 10:34:52 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1072 bytes result sent to driver
17/07/30 10:34:52 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 4 ms on localhost (1/1)
17/07/30 10:34:52 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:59) finished in 0.004 s
17/07/30 10:34:52 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/07/30 10:34:52 INFO DAGScheduler: Job 8 finished: collect at utils.scala:59, took 0.008535 s
17/07/30 10:34:52 INFO MapPartitionsRDD: Removing RDD 17 from persistence list
17/07/30 10:34:52 INFO BlockManager: Removing RDD 17
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 208.5 KB, free 447.9 KB)
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.3 KB, free 467.2 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:64359 (size: 19.3 KB, free: 511.1 MB)
17/07/30 10:34:52 INFO SparkContext: Created broadcast 14 from textFile at TextFile.scala:30
17/07/30 10:34:52 INFO FileInputFormat: Total input paths to process : 1
17/07/30 10:34:52 INFO SparkContext: Starting job: take at CsvRelation.scala:249
17/07/30 10:34:52 INFO DAGScheduler: Got job 9 (take at CsvRelation.scala:249) with 1 output partitions
17/07/30 10:34:52 INFO DAGScheduler: Final stage: ResultStage 11 (take at CsvRelation.scala:249)
17/07/30 10:34:52 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:52 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:52 INFO DAGScheduler: Submitting ResultStage 11 (C:\Users\Arjun Bansil\Documents\Citi-Bike-Analysis-R\submit.csv MapPartitionsRDD[39] at textFile at TextFile.scala:30), which has no missing parents
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.1 KB, free 470.3 KB)
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 1886.0 B, free 472.2 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:64359 (size: 1886.0 B, free: 511.1 MB)
17/07/30 10:34:52 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (C:\Users\Arjun Bansil\Documents\Citi-Bike-Analysis-R\submit.csv MapPartitionsRDD[39] at textFile at TextFile.scala:30)
17/07/30 10:34:52 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/07/30 10:34:52 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2414 bytes)
17/07/30 10:34:52 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
17/07/30 10:34:52 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:0+129528
17/07/30 10:34:52 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 2437 bytes result sent to driver
17/07/30 10:34:52 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 5 ms on localhost (1/1)
17/07/30 10:34:52 INFO DAGScheduler: ResultStage 11 (take at CsvRelation.scala:249) finished in 0.005 s
17/07/30 10:34:52 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/07/30 10:34:52 INFO DAGScheduler: Job 9 finished: take at CsvRelation.scala:249, took 0.009308 s
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 208.5 KB, free 680.7 KB)
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.3 KB, free 700.0 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:64359 (size: 19.3 KB, free: 511.1 MB)
17/07/30 10:34:52 INFO SparkContext: Created broadcast 16 from textFile at TextFile.scala:30
17/07/30 10:34:52 INFO FileInputFormat: Total input paths to process : 1
17/07/30 10:34:52 INFO SparkContext: Starting job: aggregate at InferSchema.scala:36
17/07/30 10:34:52 INFO DAGScheduler: Got job 10 (aggregate at InferSchema.scala:36) with 2 output partitions
17/07/30 10:34:52 INFO DAGScheduler: Final stage: ResultStage 12 (aggregate at InferSchema.scala:36)
17/07/30 10:34:52 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:52 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:52 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[42] at mapPartitions at CsvRelation.scala:90), which has no missing parents
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.9 KB, free 705.9 KB)
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.4 KB, free 709.3 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:64359 (size: 3.4 KB, free: 511.1 MB)
17/07/30 10:34:52 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[42] at mapPartitions at CsvRelation.scala:90)
17/07/30 10:34:52 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
17/07/30 10:34:52 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2414 bytes)
17/07/30 10:34:52 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2414 bytes)
17/07/30 10:34:52 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
17/07/30 10:34:52 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
17/07/30 10:34:52 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:129528+129528
17/07/30 10:34:52 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:0+129528
17/07/30 10:34:52 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2176 bytes result sent to driver
17/07/30 10:34:52 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2176 bytes result sent to driver
17/07/30 10:34:52 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 56 ms on localhost (1/2)
17/07/30 10:34:52 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 57 ms on localhost (2/2)
17/07/30 10:34:52 INFO DAGScheduler: ResultStage 12 (aggregate at InferSchema.scala:36) finished in 0.057 s
17/07/30 10:34:52 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/07/30 10:34:52 INFO DAGScheduler: Job 10 finished: aggregate at InferSchema.scala:36, took 0.064025 s
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 208.5 KB, free 917.8 KB)
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.3 KB, free 937.2 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:64359 (size: 19.3 KB, free: 511.0 MB)
17/07/30 10:34:52 INFO SparkContext: Created broadcast 18 from textFile at TextFile.scala:30
17/07/30 10:34:52 INFO FileInputFormat: Total input paths to process : 1
17/07/30 10:34:52 INFO SparkContext: Starting job: sql at null:-2
17/07/30 10:34:52 INFO DAGScheduler: Registering RDD 52 (sql at null:-2)
17/07/30 10:34:52 INFO DAGScheduler: Got job 11 (sql at null:-2) with 1 output partitions
17/07/30 10:34:52 INFO DAGScheduler: Final stage: ResultStage 14 (sql at null:-2)
17/07/30 10:34:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/07/30 10:34:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/07/30 10:34:52 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[52] at sql at null:-2), which has no missing parents
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 16.1 KB, free 953.3 KB)
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 961.3 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:64359 (size: 8.0 KB, free: 511.0 MB)
17/07/30 10:34:52 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[52] at sql at null:-2)
17/07/30 10:34:52 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks
17/07/30 10:34:52 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 17, localhost, partition 0,PROCESS_LOCAL, 2403 bytes)
17/07/30 10:34:52 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 18, localhost, partition 1,PROCESS_LOCAL, 2403 bytes)
17/07/30 10:34:52 INFO Executor: Running task 0.0 in stage 13.0 (TID 17)
17/07/30 10:34:52 INFO Executor: Running task 1.0 in stage 13.0 (TID 18)
17/07/30 10:34:52 INFO CacheManager: Partition rdd_49_1 not found, computing it
17/07/30 10:34:52 INFO CacheManager: Partition rdd_49_0 not found, computing it
17/07/30 10:34:52 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:129528+129528
17/07/30 10:34:52 INFO HadoopRDD: Input split: file:/C:/Users/Arjun Bansil/Documents/Citi-Bike-Analysis-R/submit.csv:0+129528
17/07/30 10:34:52 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:64359 in memory (size: 3.4 KB, free: 511.0 MB)
17/07/30 10:34:52 INFO ContextCleaner: Cleaned accumulator 33
17/07/30 10:34:52 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:64359 in memory (size: 19.3 KB, free: 511.1 MB)
17/07/30 10:34:52 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:64359 in memory (size: 1886.0 B, free: 511.1 MB)
17/07/30 10:34:52 INFO ContextCleaner: Cleaned accumulator 32
17/07/30 10:34:52 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:64359 in memory (size: 19.3 KB, free: 511.1 MB)
17/07/30 10:34:52 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:64359 in memory (size: 3.0 KB, free: 511.1 MB)
17/07/30 10:34:52 INFO ContextCleaner: Cleaned accumulator 31
17/07/30 10:34:52 INFO ContextCleaner: Cleaned accumulator 30
17/07/30 10:34:52 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:64359 in memory (size: 1224.0 B, free: 511.1 MB)
17/07/30 10:34:52 INFO ContextCleaner: Cleaned accumulator 29
17/07/30 10:34:52 INFO MemoryStore: Block rdd_49_0 stored as values in memory (estimated size 51.1 KB, free 530.9 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added rdd_49_0 in memory on localhost:64359 (size: 51.1 KB, free: 511.0 MB)
17/07/30 10:34:52 INFO MemoryStore: Block rdd_49_1 stored as values in memory (estimated size 51.1 KB, free 582.0 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added rdd_49_1 in memory on localhost:64359 (size: 51.1 KB, free: 511.0 MB)
17/07/30 10:34:52 INFO Executor: Finished task 0.0 in stage 13.0 (TID 17). 3568 bytes result sent to driver
17/07/30 10:34:52 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 17) in 74 ms on localhost (1/2)
17/07/30 10:34:52 INFO Executor: Finished task 1.0 in stage 13.0 (TID 18). 3568 bytes result sent to driver
17/07/30 10:34:52 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 18) in 81 ms on localhost (2/2)
17/07/30 10:34:52 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/07/30 10:34:52 INFO DAGScheduler: ShuffleMapStage 13 (sql at null:-2) finished in 0.081 s
17/07/30 10:34:52 INFO DAGScheduler: looking for newly runnable stages
17/07/30 10:34:52 INFO DAGScheduler: running: Set()
17/07/30 10:34:52 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/07/30 10:34:52 INFO DAGScheduler: failed: Set()
17/07/30 10:34:52 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[55] at sql at null:-2), which has no missing parents
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 9.3 KB, free 591.3 KB)
17/07/30 10:34:52 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 4.6 KB, free 595.9 KB)
17/07/30 10:34:52 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:64359 (size: 4.6 KB, free: 511.0 MB)
17/07/30 10:34:52 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[55] at sql at null:-2)
17/07/30 10:34:52 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/07/30 10:34:53 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 19, localhost, partition 0,NODE_LOCAL, 2242 bytes)
17/07/30 10:34:53 INFO Executor: Running task 0.0 in stage 14.0 (TID 19)
17/07/30 10:34:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/07/30 10:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/07/30 10:34:53 INFO Executor: Finished task 0.0 in stage 14.0 (TID 19). 1830 bytes result sent to driver
17/07/30 10:34:53 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 19) in 8 ms on localhost (1/1)
17/07/30 10:34:53 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/07/30 10:34:53 INFO DAGScheduler: ResultStage 14 (sql at null:-2) finished in 0.009 s
17/07/30 10:34:53 INFO DAGScheduler: Job 11 finished: sql at null:-2, took 0.099691 s
17/07/30 10:34:53 INFO SparkContext: Starting job: collect at utils.scala:195
17/07/30 10:34:53 INFO DAGScheduler: Got job 12 (collect at utils.scala:195) with 1 output partitions
17/07/30 10:34:53 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:195)
17/07/30 10:34:53 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:34:53 INFO DAGScheduler: Missing parents: List()
17/07/30 10:34:53 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[57] at collect at utils.scala:195), which has no missing parents
17/07/30 10:34:53 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 1968.0 B, free 597.8 KB)
17/07/30 10:34:53 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1224.0 B, free 599.0 KB)
17/07/30 10:34:53 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:64359 (size: 1224.0 B, free: 511.0 MB)
17/07/30 10:34:53 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[57] at collect at utils.scala:195)
17/07/30 10:34:53 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/07/30 10:34:53 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2348 bytes)
17/07/30 10:34:53 INFO Executor: Running task 0.0 in stage 15.0 (TID 20)
17/07/30 10:34:53 INFO Executor: Finished task 0.0 in stage 15.0 (TID 20). 940 bytes result sent to driver
17/07/30 10:34:53 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 20) in 2 ms on localhost (1/1)
17/07/30 10:34:53 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:195) finished in 0.002 s
17/07/30 10:34:53 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/07/30 10:34:53 INFO DAGScheduler: Job 12 finished: collect at utils.scala:195, took 0.005028 s
17/07/30 10:34:53 INFO ParseDriver: Parsing command: SELECT count(*) FROM `predicted`
17/07/30 10:34:53 INFO ParseDriver: Parse Completed
17/07/30 10:34:53 INFO SparkContext: Starting job: collect at utils.scala:195
17/07/30 10:34:53 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:195)
17/07/30 10:34:53 INFO DAGScheduler: Got job 13 (collect at utils.scala:195) with 1 output partitions
17/07/30 10:34:53 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:195)
17/07/30 10:34:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
17/07/30 10:34:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
17/07/30 10:34:53 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[60] at collect at utils.scala:195), which has no missing parents
17/07/30 10:34:53 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 16.2 KB, free 615.2 KB)
17/07/30 10:34:53 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 8.0 KB, free 623.2 KB)
17/07/30 10:34:53 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:64359 (size: 8.0 KB, free: 511.0 MB)
17/07/30 10:34:53 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[60] at collect at utils.scala:195)
17/07/30 10:34:53 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
17/07/30 10:34:53 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 21, localhost, partition 0,PROCESS_LOCAL, 2403 bytes)
17/07/30 10:34:53 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 22, localhost, partition 1,PROCESS_LOCAL, 2403 bytes)
17/07/30 10:34:53 INFO Executor: Running task 0.0 in stage 16.0 (TID 21)
17/07/30 10:34:53 INFO Executor: Running task 1.0 in stage 16.0 (TID 22)
17/07/30 10:34:53 INFO BlockManager: Found block rdd_49_0 locally
17/07/30 10:34:53 INFO BlockManager: Found block rdd_49_1 locally
17/07/30 10:34:53 INFO Executor: Finished task 1.0 in stage 16.0 (TID 22). 2679 bytes result sent to driver
17/07/30 10:34:53 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 22) in 18 ms on localhost (1/2)
17/07/30 10:34:53 INFO Executor: Finished task 0.0 in stage 16.0 (TID 21). 2679 bytes result sent to driver
17/07/30 10:34:53 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 21) in 19 ms on localhost (2/2)
17/07/30 10:34:53 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/07/30 10:34:53 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:195) finished in 0.021 s
17/07/30 10:34:53 INFO DAGScheduler: looking for newly runnable stages
17/07/30 10:34:53 INFO DAGScheduler: running: Set()
17/07/30 10:34:53 INFO DAGScheduler: waiting: Set(ResultStage 17)
17/07/30 10:34:53 INFO DAGScheduler: failed: Set()
17/07/30 10:34:53 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[63] at collect at utils.scala:195), which has no missing parents
17/07/30 10:34:53 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 9.4 KB, free 632.6 KB)
17/07/30 10:34:53 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.6 KB, free 637.2 KB)
17/07/30 10:34:53 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:64359 (size: 4.6 KB, free: 511.0 MB)
17/07/30 10:34:53 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
17/07/30 10:34:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[63] at collect at utils.scala:195)
17/07/30 10:34:53 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/07/30 10:34:53 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 23, localhost, partition 0,NODE_LOCAL, 2242 bytes)
17/07/30 10:34:53 INFO Executor: Running task 0.0 in stage 17.0 (TID 23)
17/07/30 10:34:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/07/30 10:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/07/30 10:34:53 INFO Executor: Finished task 0.0 in stage 17.0 (TID 23). 1830 bytes result sent to driver
17/07/30 10:34:53 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 23) in 7 ms on localhost (1/1)
17/07/30 10:34:53 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/07/30 10:34:53 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:195) finished in 0.007 s
17/07/30 10:34:53 INFO DAGScheduler: Job 13 finished: collect at utils.scala:195, took 0.037772 s
17/07/30 10:34:53 INFO ParseDriver: Parsing command: SELECT *
FROM `predicted` AS `zzz2`
WHERE (0 = 1)
17/07/30 10:34:53 INFO ParseDriver: Parse Completed
17/07/30 10:35:11 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
17/07/30 10:35:11 INFO audit: ugi=Arjun Bansil	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
17/07/30 10:35:11 INFO SparkContext: Starting job: collect at utils.scala:195
17/07/30 10:35:11 INFO DAGScheduler: Got job 14 (collect at utils.scala:195) with 1 output partitions
17/07/30 10:35:11 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:195)
17/07/30 10:35:11 INFO DAGScheduler: Parents of final stage: List()
17/07/30 10:35:11 INFO DAGScheduler: Missing parents: List()
17/07/30 10:35:11 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[65] at collect at utils.scala:195), which has no missing parents
17/07/30 10:35:11 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 1968.0 B, free 639.2 KB)
17/07/30 10:35:11 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1224.0 B, free 640.4 KB)
17/07/30 10:35:11 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:64359 (size: 1224.0 B, free: 511.0 MB)
17/07/30 10:35:11 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
17/07/30 10:35:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[65] at collect at utils.scala:195)
17/07/30 10:35:11 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/07/30 10:35:11 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2651 bytes)
17/07/30 10:35:11 INFO Executor: Running task 0.0 in stage 18.0 (TID 24)
17/07/30 10:35:11 INFO Executor: Finished task 0.0 in stage 18.0 (TID 24). 1263 bytes result sent to driver
17/07/30 10:35:11 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 24) in 2 ms on localhost (1/1)
17/07/30 10:35:11 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/07/30 10:35:11 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:195) finished in 0.002 s
17/07/30 10:35:11 INFO DAGScheduler: Job 14 finished: collect at utils.scala:195, took 0.006613 s
17/07/30 11:01:37 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:64359 in memory (size: 1224.0 B, free: 511.0 MB)
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 56
17/07/30 11:01:37 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:64359 in memory (size: 4.6 KB, free: 511.0 MB)
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 55
17/07/30 11:01:37 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:64359 in memory (size: 8.0 KB, free: 511.0 MB)
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 54
17/07/30 11:01:37 INFO ContextCleaner: Cleaned shuffle 3
17/07/30 11:01:37 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:64359 in memory (size: 1224.0 B, free: 511.0 MB)
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 45
17/07/30 11:01:37 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:64359 in memory (size: 4.6 KB, free: 511.0 MB)
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 44
17/07/30 11:01:37 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:64359 in memory (size: 8.0 KB, free: 511.0 MB)
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 43
17/07/30 11:01:37 INFO ContextCleaner: Cleaned shuffle 2
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 42
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 41
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 40
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 39
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 38
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 37
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 36
17/07/30 11:01:37 INFO ContextCleaner: Cleaned accumulator 35
